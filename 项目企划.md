### 1. **准备数据集**

- 根据 `readme.txt` 中的要求，首先需要将 `train` 数据集进行划分。
    - **划分任务**：将 `train` 数据集中一部分划分到 `you_can_make_it.json` 中，并从原数据集中删除这些记录，确保没有重叠的数据。可以通过随机选择的方式划分数据，具体划分比例可以参考需求文档。
    - **工具**：你可以使用 Python 读取 `query_train_18000.json` 文件，将其划分并保存为 `you_can_make_it.json` 文件。

### 2. **解析与特征提取**

- 使用 **`range_query.py`** 中的 `ParsedRangeQuery` 类对查询进行解析，将查询的范围条件提取出来。你可以测试这部分功能，确保它能够正确解析 SQL 查询​(range_query)。
    
- 接下来，使用 **`learn_from_query.py`** 中的 `extract_features_from_query` 函数，对解析后的查询提取特征（如列的范围值）。这将为后续的机器学习模型训练做准备​(learn_from_query)。
    

### 3. **训练模型**

- 在解析和提取特征完成后，进入模型训练阶段。可以使用 **`learn_from_query.py`** 中的 `est_AI1` 和 `est_AI2` 模型进行训练。
    - **数据预处理**：确保在训练之前，查询数据和相应的标签（实际行数）已被转化为适合模型输入的特征和标签对​(learn_from_query)。
    - **模型选择**：你可以先从 `est_AI1` 开始，确保其工作正常，然后再尝试 `est_AI2`，比较它们的性能。

### 4. **生成评估报告**

- 使用 **`evaluation.py`** 来评估模型的性能。该文件会根据测试数据生成误差分布（如 p50, p80, p90 等），并绘制预测值与实际值的对比图。
    - **报告生成**：运行 `gen_report` 函数，生成模型的误差评估报告​(evaluation)。

### 5. **验证与优化**

- 最后，使用 `test_result.py` 运行简单测试，确保模型的各部分（如 `act` 和 `AI1`, `AI2` 的输出长度一致）工作正常​(test_result)。

### 建议的初步步骤：

1. **数据集划分**：完成 `train` 数据的划分。
2. **解析和特征提取**：测试 `range_query.py` 的解析功能，提取特征。
3. **模型训练**：使用 `learn_from_query.py` 训练模型。
4. **生成报告**：运行 `evaluation.py` 来生成报告。